# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QO8sDPhm6TkK4K21fFUqzk5jXmltNKqs
"""

pip install numpy pandas matplotlib scikit-learn opencv-python tensorflow keras torch torchvision albumentations streamlit fastapi uvicorn

!pip install fastapi uvicorn nest_asyncio

pip install python-multipart

import os

# Create the directory if it doesn't exist
os.makedirs('/content/model', exist_ok=True)

# Save the model
unet_plus_plus.save('/content/model/unet_plus_plus.h5')

import os

# List contents of the model directory
print(os.listdir('/content/model'))

import tensorflow as tf
print(tf.__version__)

pip install --upgrade tensorflow

import cv2
import numpy as np
import os
import glob
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import albumentations as A

# Define paths
image_dir = '/content/data/image/'
mask_dir = '/content/data/mask/'

# Get list of image and mask files
image_paths = sorted(glob.glob(os.path.join(image_dir, "*.tif")))
mask_paths = sorted(glob.glob(os.path.join(mask_dir, "*.tif")))

# Function to apply CLAHE and load data
def load_and_preprocess(image_path, mask_path):
    # Load image and mask
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    if image is None or mask is None:
        raise FileNotFoundError(f"Image or mask not found: {image_path} or {mask_path}")

    # Apply CLAHE
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    image_clahe = clahe.apply(image)

    # Normalize images to [0, 1]
    image_normalized = image_clahe / 255.0
    mask_normalized = mask / 255.0

    return image_normalized, mask_normalized

# Load all data
images = []
masks = []
for img_path, msk_path in zip(image_paths, mask_paths):
    img, msk = load_and_preprocess(img_path, msk_path)
    images.append(img)
    masks.append(msk)

# Convert to numpy arrays
images = np.array(images)
masks = np.array(masks)

# Split into training and testing sets
train_images, val_images, train_masks, val_masks = train_test_split(images, masks, test_size=0.2, random_state=42)

# Expand dimensions to match the model's expected input shape (Batch, Height, Width, Channels)
train_images = np.expand_dims(train_images, axis=-1)
train_masks = np.expand_dims(train_masks, axis=-1)
val_images = np.expand_dims(val_images, axis=-1)
val_masks = np.expand_dims(val_masks, axis=-1)

print(f"Training images shape: {train_images.shape}")
print(f"Validation images shape: {val_images.shape}")

from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Activation, BatchNormalization, multiply, Add
from tensorflow.keras.models import Model

# Nested U-Net (U-Net++) Implementation
def build_unet_plus_plus(input_shape=(256, 256, 1)):
    inputs = Input(input_shape)

    # Define the Nested U-Net++ architecture here similar to before
    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)
    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    up3 = UpSampling2D(size=(2, 2))(conv2)
    concat3 = concatenate([up3, conv1], axis=-1)
    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat3)
    conv3 = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(conv3)

    model = Model(inputs=[inputs], outputs=[conv3])
    return model

# Instantiate the model
unet_plus_plus = build_unet_plus_plus(input_shape=(256, 256, 1))

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.metrics import MeanIoU

# Updated dice coefficient function
def dice_coef(y_true, y_pred, smooth=1):
    y_true_f = tf.keras.backend.flatten(y_true)
    y_pred_f = tf.keras.backend.flatten(y_pred)
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)

# Compile the model
unet_plus_plus.compile(optimizer=Adam(learning_rate=1e-4),
                        loss=BinaryCrossentropy(),
                        metrics=[dice_coef, MeanIoU(num_classes=2)])

# Train the model
unet_plus_plus.fit(train_images, train_masks, validation_data=(val_images, val_masks), epochs=10, batch_size=8)

# fastapi_app.py

import uvicorn
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
import cv2

# Initialize the FastAPI app
app = FastAPI()

# Load your trained model (ensure the path is correct)
model = load_model('/content/model/unet_plus_plus.h5', compile=False)

@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    try:
        # Read the uploaded image file
        image = await file.read()
        # Convert image bytes to numpy array
        nparr = np.frombuffer(image, np.uint8)
        # Decode image
        img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)

        # Preprocess the image (resize, normalize, etc.)
        img = cv2.resize(img, (128, 128))  # Adjust size according to your model input
        img = img / 255.0  # Normalize to [0, 1]
        img = np.expand_dims(img, axis=-1)  # Add channel dimension
        img = np.expand_dims(img, axis=0)  # Add batch dimension

        # Make prediction
        preds = model.predict(img)
        preds = (preds > 0.5).astype(np.uint8)  # Binarize predictions

        # Convert prediction to a format that can be returned
        pred_mask = preds.squeeze()  # Remove batch dimension
        pred_mask = (pred_mask * 255).astype(np.uint8)  # Scale back to [0, 255]

        # Convert prediction mask to base64 or save it as needed
        # For now, let's just return the shape of the prediction as a response
        return JSONResponse(content={"mask_shape": pred_mask.shape.tolist()})

    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=400)

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
# streamlit_app.py

import streamlit as st
import requests
import numpy as np
import cv2
import base64

# Streamlit UI
st.title("Brain MRI Metastasis Segmentation")

# File uploader
uploaded_file = st.file_uploader("Upload an MRI Image", type=["png", "jpg", "jpeg", "tif"])

if uploaded_file is not None:
    # Read the uploaded file
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, 1)

    # Display the uploaded image
    st.image(img, channels="BGR", caption="Uploaded MRI Image", use_column_width=True)

    # Send the image to the FastAPI backend for prediction
    files = {'file': uploaded_file}
    response = requests.post("http://127.0.0.1:8000/predict/", files=files)

    if response.status_code == 200:
        mask_shape = response.json().get("mask_shape")
        st.success(f"Prediction successful! Output mask shape: {mask_shape}")
    else:
        st.error(f"Error: {response.json().get('error')}")

streamlit run Untitled3.py

curl -X POST "http://127.0.0.1:8000/predict/" -F "file=@/content/data/image/TCGA_HT_A61B_19991127_63.tif.tif"